# -*- coding: utf-8 -*-
"""ESRGAN PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-2JrZ0zHnOeBUSRrXNqaLznddS4HrdZ
"""

!pip install torch torchvision
!pip install numpy opencv-python tqdm
!pip install tensorboardX

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import transforms
from torchvision.utils import save_image
from PIL import Image
import os
from tqdm import tqdm
from tensorboardX import SummaryWriter

class ResidualBlock(nn.Module):
    def __init__(self):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.prelu = nn.PReLU()
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

    def forward(self, x):
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.prelu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        out += x
        return out

class Generator(nn.Module):
    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):
        super(Generator, self).__init__()

        # Initial convolution block
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4)
        self.prelu = nn.PReLU()

        # Residual blocks
        res_blocks = []
        for _ in range(n_residual_blocks):
            res_blocks.append(ResidualBlock())
        self.res_blocks = nn.Sequential(*res_blocks)

        # Second conv block after residual blocks
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

        # Final output layer
        self.conv3 = nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4)

    def forward(self, x):
        out1 = self.prelu(self.conv1(x))
        out = self.res_blocks(out1)
        out = self.bn2(self.conv2(out))
        out = out1 + out
        out = self.conv3(out)
        return out

class Discriminator(nn.Module):
    def __init__(self, in_channels=3):
        super(Discriminator, self).__init__()

        def discriminator_block(in_filters, out_filters, stride=1, normalize=True):
            layers = [nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=stride, padding=1)]
            if normalize:
                layers.append(nn.BatchNorm2d(out_filters))
            layers.append(nn.LeakyReLU(0.2, inplace=True))
            return layers

        self.model = nn.Sequential(
            *discriminator_block(in_channels, 64, normalize=False),
            *discriminator_block(64, 64, stride=2),
            *discriminator_block(64, 128),
            *discriminator_block(128, 128, stride=2),
            *discriminator_block(128, 256),
            *discriminator_block(256, 256, stride=2),
            *discriminator_block(256, 512),
            *discriminator_block(512, 512, stride=2),
            nn.Conv2d(512, 1, kernel_size=3, stride=1, padding=1)
        )

    def forward(self, img):
        return self.model(img)

class ImageDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.lr_images = sorted(os.listdir(lr_dir))
        self.hr_images = sorted(os.listdir(hr_dir))
        self.transform = transform

    def __len__(self):
        return len(self.lr_images)

    def __getitem__(self, index):
        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_images[index])).convert('RGB')
        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_images[index])).convert('RGB')

        if self.transform:
            lr_image = self.transform(lr_image)
            hr_image = self.transform(hr_image)

        return lr_image, hr_image

transform = transforms.Compose([
    transforms.ToTensor()
])

# Assuming the Generator, Discriminator, and ImageDataset classes are defined as before

lr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/low_res'
hr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/high_res'
batch_size = 16

# Load and preprocess the test image
transform = ToTensor()
lr_image = load_image(test_image_path, transform).unsqueeze(0).to(device)

train_dataset = ImageDataset(lr_dir, hr_dir, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

generator = Generator().to(device)
discriminator = Discriminator().to(device)

criterion_GAN = nn.BCEWithLogitsLoss().to(device)
criterion_content = nn.L1Loss().to(device)

optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

num_epochs = 100
log_dir = 'logs'
writer = SummaryWriter(log_dir)

for epoch in range(num_epochs):
    generator.train()
    discriminator.train()
    for i, (lr, hr) in enumerate(tqdm(train_dataloader)):
        lr = lr.to(device)
        hr = hr.to(device)

        # Train Discriminator
        optimizer_D.zero_grad()
        fake_hr = generator(lr)
        real_out = discriminator(hr)
        fake_out = discriminator(fake_hr.detach())
        real_loss = criterion_GAN(real_out - torch.mean(fake_out), torch.ones_like(real_out))
        fake_loss = criterion_GAN(fake_out - torch.mean(real_out), torch.zeros_like(fake_out))
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward(retain_graph=True)
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        fake_out = discriminator(fake_hr)
        g_loss_GAN = criterion_GAN(fake_out - torch.mean(real_out.detach()), torch.ones_like(fake_out))
        g_loss_content = criterion_content(fake_hr, hr)
        g_loss = g_loss_GAN + 1e-2 * g_loss_content
        g_loss.backward()
        optimizer_G.step()

        # Logging
        writer.add_scalar('Loss/Discriminator', d_loss.item(), epoch * len(train_dataloader) + i)
        writer.add_scalar('Loss/Generator', g_loss.item(), epoch * len(train_dataloader) + i)

    print(f"Epoch [{epoch + 1}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}")

    # Save the models after each epoch
    torch.save(generator.state_dict(), f'/content/drive/MyDrive/AI/Term 3/dataset/generator_epoch_{epoch+1}.pth')
    torch.save(discriminator.state_dict(), f'/content/drive/MyDrive/AI/Term 3/dataset/discriminator_epoch_{epoch+1}.pth')

writer.close()

# Save the final models
torch.save(generator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/generator_final.pth')
torch.save(discriminator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/discriminator_final.pth')

import torch
from torchvision.transforms import ToTensor, ToPILImage
from PIL import Image
import matplotlib.pyplot as plt

# Assuming the Generator class is defined as before

# Path to the saved generator model
generator_model_path = '/content/drive/MyDrive/AI/Term 3/dataset/best_generator_tom.pth'


# Load the trained generator model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
generator = Generator().to(device)
generator.load_state_dict(torch.load(generator_model_path, map_location=device))
generator.eval()

# Function to load and preprocess a low-resolution image
def load_image(image_path, transform=None):
    image = Image.open(image_path).convert('RGB')
    if transform:
        image = transform(image)
    return image

# Path to the low-resolution test image
test_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/val/low_res/0.png'

# Load and preprocess the test image
transform = ToTensor()
lr_image = load_image(test_image_path, transform).unsqueeze(0).to(device)

# Generate the high-resolution image
with torch.no_grad():
    sr_image = generator(lr_image).squeeze(0).cpu()

# Convert the tensor to PIL image
to_pil_image = ToPILImage()
sr_image = to_pil_image(sr_image)

# Save the generated high-resolution image
output_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/Test Saved images/generated_sample1.jpg'
sr_image.save(output_image_path)

# Display the low-resolution and high-resolution images
lr_image = lr_image.squeeze(0).cpu()
lr_image = to_pil_image(lr_image)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Low-Resolution Image')
plt.imshow(lr_image)
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title('Generated High-Resolution Image')
plt.imshow(sr_image)
plt.axis('off')

plt.show()

from google.colab import drive
drive.mount('/content/drive')

import torch
from torchvision.transforms import ToTensor, ToPILImage
from PIL import Image
import matplotlib.pyplot as plt

# Assuming the Generator class is defined as before

# Path to the saved generator model
generator_model_path = '/content/drive/MyDrive/AI/Term 3/dataset/best_generator_tom.pth'

# Load the trained generator model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
generator = Generator().to(device)
generator.load_state_dict(torch.load(generator_model_path, map_location=device))
generator.eval()

# Function to load and preprocess a low-resolution image
def load_image(image_path, transform=None):
    image = Image.open(image_path).convert('RGB')
    if transform:
        image = transform(image)
    return image

# Path to the low-resolution test image
test_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/val/low_res/0.png'

# Load and preprocess the test image
transform = ToTensor()
lr_image = load_image(test_image_path, transform).unsqueeze(0).to(device)

# Check the input shape
print(f"Low-resolution image shape: {lr_image.shape}")

# Generate the high-resolution image
with torch.no_grad():
    sr_image = generator(lr_image).squeeze(0).cpu()

# Check the output shape
print(f"Generated high-resolution image shape: {sr_image.shape}")

# Convert the tensor to PIL image
to_pil_image = ToPILImage()
sr_image = to_pil_image(sr_image)

# Save the generated high-resolution image
output_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/Test Saved images/generated_sample2.jpg'
sr_image.save(output_image_path)

# Display the low-resolution and high-resolution images
lr_image = lr_image.squeeze(0).cpu()
lr_image = to_pil_image(lr_image)

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.title('Low-Resolution Image')
plt.imshow(lr_image)
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title('Generated High-Resolution Image')
plt.imshow(sr_image)
plt.axis('off')

plt.show()

# For further debugging: visualize intermediate layers of the generator
def visualize_intermediate_output(generator, lr_image):
    activations = []
    hooks = []

    def hook_fn(module, input, output):
        activations.append(output)

    # Register hooks to capture the output of each layer
    for name, layer in generator.named_children():
        hooks.append(layer.register_forward_hook(hook_fn))

    # Pass the image through the network
    with torch.no_grad():
        _ = generator(lr_image)

    # Remove hooks
    for hook in hooks:
        hook.remove()

    # Visualize the activations
    for i, activation in enumerate(activations):
        activation = activation.squeeze(0).cpu()
        fig, axarr = plt.subplots(min(activation.size(0), 8), 8, figsize=(12, 12))
        for idx in range(min(activation.size(0), 64)):
            ax = axarr[idx // 8, idx % 8]
            ax.imshow(activation[idx].detach().numpy(), cmap='viridis')
            ax.axis('off')
        plt.suptitle(f'Layer {i+1} Activations')
        plt.show()

# Visualize intermediate outputs
visualize_intermediate_output(generator, lr_image)





from keras import layers
def down(filters , kernel_size, apply_batch_normalization = True):
    downsample = tf.keras.models.Sequential()
    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))
    downsample.add(layers.Dropout(.2))
    if apply_batch_normalization:
        downsample.add(layers.BatchNormalization())
    downsample.add(keras.layers.LeakyReLU())
    return downsample

def up(filters, kernel_size, dropout = False):
    upsample = tf.keras.models.Sequential()
    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))
    upsample.add(layers.Dropout(.2))
    if dropout:
        upsample.dropout(0.2)
    upsample.add(keras.layers.LeakyReLU())
    return upsample

def model():
    inputs = layers.Input(shape= [SIZE,SIZE,3])
    d1 = down(128,(3,3),False)(inputs)
    d2 = down(128,(3,3),False)(d1)
    d3 = down(256,(3,3),True)(d2)
    d4 = down(512,(3,3),True)(d3)

    d5 = down(512,(3,3),True)(d4)
    #upsampling
    u1 = up(512,(3,3),False)(d5)
    u1 = layers.concatenate([u1,d4])
    u2 = up(256,(3,3),False)(u1)
    u2 = layers.concatenate([u2,d3])
    u3 = up(128,(3,3),False)(u2)
    u3 = layers.concatenate([u3,d2])
    u4 = up(128,(3,3),False)(u3)
    u4 = layers.concatenate([u4,d1])
    u5 = up(3,(3,3),False)(u4)
    u5 = layers.concatenate([u5,inputs])
    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)
    return tf.keras.Model(inputs=inputs, outputs=output)

model = model()
model.summary()







lr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/low_res'
hr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/high_res'
batch_size = 16

train_dataset = ImageDataset(lr_dir, hr_dir, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

generator = Generator().to(device)
discriminator = Discriminator().to(device)

criterion_GAN = nn.BCEWithLogitsLoss().to(device)
criterion_content = nn.L1Loss().to(device)

optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

num_epochs = 5
log_dir = 'logs'
writer = SummaryWriter(log_dir)

for epoch in range(num_epochs):
    generator.train()
    discriminator.train()
    for i, (lr, hr) in enumerate(tqdm(train_dataloader)):
        lr = lr.to(device)
        hr = hr.to(device)

        # Train Discriminator
        optimizer_D.zero_grad()
        fake_hr = generator(lr)
        real_out = discriminator(hr)
        fake_out = discriminator(fake_hr.detach())
        real_loss = criterion_GAN(real_out - torch.mean(fake_out), torch.ones_like(real_out))
        fake_loss = criterion_GAN(fake_out - torch.mean(real_out), torch.zeros_like(fake_out))
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward(retain_graph=True)
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        fake_out = discriminator(fake_hr)
        g_loss_GAN = criterion_GAN(fake_out - torch.mean(real_out.detach()), torch.ones_like(fake_out))
        g_loss_content = criterion_content(fake_hr, hr)
        g_loss = g_loss_GAN + 1e-2 * g_loss_content
        g_loss.backward()
        optimizer_G.step()

        # Logging
        writer.add_scalar('Loss/Discriminator', d_loss.item(), epoch * len(train_dataloader) + i)
        writer.add_scalar('Loss/Generator', g_loss.item(), epoch * len(train_dataloader) + i)

    print(f"Epoch [{epoch + 1}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}")

writer.close()

# Save the models
torch.save(generator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/generator.pth')
torch.save(discriminator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/discriminator.pth')

import torch
from torchvision.transforms import ToPILImage
from PIL import Image

# Define your Generator model (assuming it's defined similar to before)
generator = Generator()
generator.load_state_dict(torch.load('/content/drive/MyDrive/AI/Term 3/dataset/generator.pth'))
generator.eval()  # Set the model to evaluation mode
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
generator.to(device)

from torchvision.transforms import ToTensor

# Example of loading a test image
test_image_path = '/content/drive/MyDrive/AI/Term 3/dataset/test/low_res/test_image.jpg'
test_image = Image.open(test_image_path).convert('RGB')

# Define transformations
transform = ToTensor()

# Preprocess the image (assuming it's a PIL Image)
lr_image = transform(test_image).unsqueeze(0).to(device)  # Add batch dimension and move to device

# Generate high-resolution image
with torch.no_grad():
    hr_image = generator(lr_image).detach().cpu()

# Convert tensor to PIL Image
to_pil = ToPILImage()
generated_hr_image = to_pil(hr_image.squeeze(0))  # Remove batch dimension and convert to PIL Image

import matplotlib.pyplot as plt

# Display the generated high-resolution image
plt.figure(figsize=(8, 8))
plt.imshow(generated_hr_image)
plt.axis('off')
plt.title('Generated High-Resolution Image')
plt.show()

# Save the generated image
generated_hr_image.save('/content/drive/MyDrive/AI/Term 3/dataset/test/generated_hr_image.jpg')





lr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/low_res'
hr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/high_res'
batch_size = 16

train_dataset = ImageDataset(lr_dir, hr_dir, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

generator = Generator().to(device)
discriminator = Discriminator().to(device)

criterion_GAN = nn.BCEWithLogitsLoss().to(device)
criterion_content = nn.L1Loss().to(device)

optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

num_epochs = 10
log_dir = 'logs'
writer = SummaryWriter(log_dir)

for epoch in range(num_epochs):
    generator.train()
    discriminator.train()
    for i, (lr, hr) in enumerate(tqdm(train_dataloader)):
        lr = lr.to(device)
        hr = hr.to(device)

        # Train Discriminator
        optimizer_D.zero_grad()
        fake_hr = generator(lr)
        real_out = discriminator(hr)
        fake_out = discriminator(fake_hr.detach())
        real_loss = criterion_GAN(real_out - torch.mean(fake_out), torch.ones_like(real_out))
        fake_loss = criterion_GAN(fake_out - torch.mean(real_out), torch.zeros_like(fake_out))
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        fake_out = discriminator(fake_hr)
        g_loss_GAN = criterion_GAN(fake_out - torch.mean(real_out), torch.ones_like(fake_out))
        g_loss_content = criterion_content(fake_hr, hr)
        g_loss = g_loss_GAN + 1e-2 * g_loss_content
        g_loss.backward()
        optimizer_G.step()

        # Logging
        writer.add_scalar('Loss/Discriminator', d_loss.item(), epoch * len(train_dataloader) + i)
        writer.add_scalar('Loss/Generator', g_loss.item(), epoch * len(train_dataloader) + i)

    print(f"Epoch [{epoch + 1}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}")

writer.close()

# Save the models
torch.save(generator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/generator.pth')
torch.save(discriminator.state_dict(), '/content/drive/MyDrive/AI/Term 3/dataset/discriminator.pth')









import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import cv2
from tqdm import tqdm
from tensorboardX import SummaryWriter

class ImageDataset(Dataset):
    def __init__(self, lr_dir, hr_dir, transform=None):
        self.lr_dir = lr_dir
        self.hr_dir = hr_dir
        self.transform = transform
        self.lr_images = os.listdir(lr_dir)
        self.hr_images = os.listdir(hr_dir)

    def __len__(self):
        return len(self.lr_images)

    def __getitem__(self, idx):
        lr_image = cv2.imread(os.path.join(self.lr_dir, self.lr_images[idx]))
        hr_image = cv2.imread(os.path.join(self.hr_dir, self.hr_images[idx]))

        if self.transform:
            lr_image = self.transform(lr_image)
            hr_image = self.transform(hr_image)

        return lr_image, hr_image

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

lr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/low_res'
hr_dir = '/content/drive/MyDrive/AI/Term 3/dataset/train/high_res'

dataset = ImageDataset(lr_dir, hr_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

class Generator(nn.Module):
    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):
        super(Generator, self).__init__()

        # Initial convolution block
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4)
        self.prelu = nn.PReLU()

        # Residual blocks
        res_blocks = []
        for _ in range(n_residual_blocks):
            res_blocks.append(ResidualBlock())
        self.res_blocks = nn.Sequential(*res_blocks)

        # Second conv block after residual blocks
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(64)

        # Upsampling blocks
        self.upsample1 = UpsampleBlock(64, 256)
        self.upsample2 = UpsampleBlock(64, 256)

        # Final output layer
        self.conv3 = nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4)

    def forward(self, x):
        out1 = self.prelu(self.conv1(x))
        out = self.res_blocks(out1)
        out = self.bn2(self.conv2(out))
        out = out1 + out
        out = self.upsample1(out)
        out = self.upsample2(out)
        out = self.conv3(out)
        return out

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.net = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(512, 1024, kernel_size=1, stride=1, padding=0),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(1024, 1, kernel_size=1, stride=1, padding=0)
        )

    def forward(self, x):
        return self.net(x)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.utils import save_image
from tqdm import tqdm
from tensorboardX import SummaryWriter
import os

class ResidualBlock(nn.Module):
    def __init__(self):
        super(ResidualBlock, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.PReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64)
        )

    def forward(self, x):
        return x + self.block(x)

class UpsampleBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UpsampleBlock, self).__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),
            nn.PixelShuffle(2),
            nn.PReLU()
        )

    def forward(self, x):
        return self.block(x)

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4)
        self.prelu = nn.PReLU()
        self.res_blocks = self.make_layers(ResidualBlock, 16)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)
        self.bn = nn.BatchNorm2d(64)
        self.upsample1 = UpsampleBlock(64, 256)
        self.upsample2 = UpsampleBlock(64, 256)
        self.conv3 = nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4)

    def make_layers(self, block, num_blocks):
        layers = []
        for _ in range(num_blocks):
            layers.append(block())
        return nn.Sequential(*layers)

    def forward(self, x):
        out1 = self.prelu(self.conv1(x))
        out = self.res_blocks(out1)
        out = self.bn(self.conv2(out))
        out = out1 + out
        out = self.upsample1(out)
        out = self.upsample2(out)
        out = self.conv3(out)
        return out

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.net = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(512, 1024, kernel_size=1, stride=1, padding=0),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(1024, 1, kernel_size=1, stride=1, padding=0)
        )

    def forward(self, x):
        return self.net(x)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

generator = Generator().to(device)
discriminator = Discriminator().to(device)

criterion_GAN = nn.BCEWithLogitsLoss().to(device)
criterion_content = nn.L1Loss().to(device)

optimizer_G = optim.Adam(generator.parameters(), lr=1e-4)
optimizer_D = optim.Adam(discriminator.parameters(), lr=1e-4)

num_epochs = 10
log_dir = 'logs'
writer = SummaryWriter(log_dir)

for epoch in range(num_epochs):
    generator.train()
    discriminator.train()
    for i, (lr, hr) in enumerate(tqdm(dataloader)):
        lr = lr.to(device)
        hr = hr.to(device)

# Train Discriminator
        optimizer_D.zero_grad()
        fake_hr = generator(lr)
        real_out = discriminator(hr)
        fake_out = discriminator(fake_hr.detach())
        real_loss = criterion_GAN(real_out - torch.mean(fake_out), torch.ones_like(real_out))
        fake_loss = criterion_GAN(fake_out - torch.mean(real_out), torch.zeros_like(fake_out))
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # Train Generator
        optimizer_G.zero_grad()
        fake_out = discriminator(fake_hr)
        g_loss_GAN = criterion_GAN(fake_out - torch.mean(real_out), torch.ones_like(fake_out))
        g_loss_content = criterion_content(fake_hr, hr)
        g_loss = g_loss_GAN + 1e-2 * g_loss_content
        g_loss.backward()
        optimizer_G.step()

        # Logging
        writer.add_scalar('Loss/Discriminator', d_loss.item(), epoch * len(dataloader) + i)
        writer.add_scalar('Loss/Generator', g_loss.item(), epoch * len(dataloader) + i)

print(f"Epoch [{epoch + 1}/{num_epochs}] Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f}")

writer.close()

# Save the models
torch.save(generator.state_dict(), 'generator.pth')
torch.save(discriminator.state_dict(), 'discriminator.pth')





